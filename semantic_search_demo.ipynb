{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Semantic Search Engine Demo\n",
        "\n",
        "This notebook demonstrates how to use semantic embeddings to perform semantic search. Semantic search understands the *meaning* of text, not just keyword matching.\n",
        "\n",
        "## What You'll Learn\n",
        "- How to use pre-trained embedding models\n",
        "- How to convert text into numerical vectors (embeddings)\n",
        "- How to find semantically similar documents using cosine similarity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Required Libraries\n",
        "\n",
        "First, we need to install the necessary libraries. Run this cell once to install the dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install the necessary library\n",
        "%pip install sentence-transformers numpy scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Import Libraries\n",
        "\n",
        "Import the required libraries for our semantic search implementation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load the Embedding Model\n",
        "\n",
        "We'll use a pre-trained model from Hugging Face. The `all-MiniLM-L6-v2` model is a lightweight but effective model that converts text into 384-dimensional vectors.\n",
        "\n",
        "**Note:** The first time you run this, it will download the model (about 80MB). Subsequent runs will use the cached version.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 1. Load the Embedding Model ---\n",
        "# This loads the model from the Hugging Face Hub (sentence-transformers/all-MiniLM-L6-v2)\n",
        "print(\"Loading model...\")\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"Model loaded successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Define the Knowledge Base (Corpus)\n",
        "\n",
        "This is our collection of documents that we want to search through. In a real application, this could be thousands or millions of documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 2. Define the Knowledge Base (Corpus) ---\n",
        "documents = [\n",
        "    \"The sky is a vivid shade of blue today.\",\n",
        "    \"The newest iPhone model was released with a powerful new chip.\",\n",
        "    \"A majestic hawk was spotted flying high above the forest canopy.\",\n",
        "    \"Apple is set to announce its latest mobile device with updated features.\",\n",
        "    \"I'm enjoying a picnic on the grass.\",\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Create Embeddings for the Corpus\n",
        "\n",
        "Convert each document in our corpus into a numerical vector (embedding). These embeddings capture the semantic meaning of the text.\n",
        "\n",
        "**Key Concept:** Similar meanings will have similar vectors, even if they use different words!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 3. Create Embeddings for the Corpus ---\n",
        "# The .encode() function converts the text into numerical vectors (embeddings)\n",
        "document_embeddings = model.encode(documents, convert_to_tensor=True)\n",
        "print(f\"Generated {len(document_embeddings)} embeddings, each with a dimension of {document_embeddings.shape[1]}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Define a Query and Create its Embedding\n",
        "\n",
        "Now we'll create a search query. Notice that our query doesn't use the exact same words as the documents, but it should still find the relevant document about phones!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 4. Define a Query and Create its Embedding ---\n",
        "query = \"Tell me about the recent phone technology releases.\"\n",
        "query_embedding = model.encode([query], convert_to_tensor=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Perform Semantic Search (Calculate Similarity)\n",
        "\n",
        "We calculate the cosine similarity between the query embedding and all document embeddings.\n",
        "\n",
        "**Cosine Similarity:**\n",
        "- Ranges from -1 (opposite meaning) to 1 (identical meaning)\n",
        "- Values close to 1 indicate high semantic similarity\n",
        "- Values close to 0 indicate low similarity\n",
        "\n",
        "We'll find the document with the highest similarity score.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 5. Perform Semantic Search (Calculate Similarity) ---\n",
        "# We calculate the cosine similarity between the query embedding and ALL document embeddings.\n",
        "# Cosine similarity ranges from -1 (opposite meaning) to 1 (identical meaning).\n",
        "similarities = cosine_similarity(query_embedding.cpu().numpy(), document_embeddings.cpu().numpy())\n",
        "\n",
        "# Get the index of the most similar document\n",
        "most_similar_index = np.argmax(similarities)\n",
        "max_similarity_score = similarities[0, most_similar_index]\n",
        "best_match_document = documents[most_similar_index]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Display Results\n",
        "\n",
        "Let's see which document was found as the best match for our query!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 6. Print Results ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"Query: **{query}**\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Best Match (Score: {max_similarity_score:.4f}):\")\n",
        "print(f\"'{best_match_document}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Explore All Similarity Scores (Optional)\n",
        "\n",
        "Let's see the similarity scores for all documents to better understand how the semantic search works.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display similarity scores for all documents\n",
        "print(\"\\nSimilarity scores for all documents:\")\n",
        "print(\"-\" * 50)\n",
        "for i, (doc, score) in enumerate(zip(documents, similarities[0])):\n",
        "    print(f\"\\nDocument {i+1} (Score: {score:.4f}):\")\n",
        "    print(f\"  '{doc}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Try It Yourself!\n",
        "\n",
        "Experiment with different queries to see how semantic search works:\n",
        "\n",
        "- Try queries about nature, technology, or daily activities\n",
        "- Notice how the model finds relevant documents even when they don't share exact keywords\n",
        "- Compare the similarity scores to understand the ranking\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
